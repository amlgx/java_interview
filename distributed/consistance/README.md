# 分布式锁



## 分布式锁的作用是什么？

分布式系统需要解决数据一致性的问题，就会用到分布式锁。

## 一致性有几种？

强一致性，最终一致性，用户一致性。

## Lease租期机制

授权者主节点承诺在约定时间内不修改数据，从节点可以放心使用。过期后，从节点删除数据，主节点阻塞到所有从节点都过期，再更新租期数据。那么，早失效的节点就要锁定服务，影响可用性。解决方案包括：更新为没有租期的临时数据。提前主动通知失效。业务上不相关的资源，可以按照锁分离策略，解除锁定。

# 分布式事务

## 分布式事务的实现有哪些？

XA协议，提供回滚接口，本地消息表

## XA协议

两阶段提交协议(如XA)在主流的关系型数据库中广泛使用。JTA（java事务API）是符合XOpen组织的DTP(分布式事务处理)模型，该模型中TM(事务管理器)和RM(资源管理器)之间的接口就是XA协议。Tomcat没有实现JTA, 需要借助Jotm等来实现，可以由spring事务整合。部署在linux平台的mysql不支持分布式事务。

这种方法实现简单，适合传统单体应用，在同一个方法中跨库操作，对性能影响大。

## 提供回滚接口

服务化架构中一个功能需要协调多个原子服务，如果要求同步返回结果，就可以采用串行调用、失败回滚的方式。除了优先调用的回滚接口，还可以通过传参实现。

这种方法适合串行服务少、回滚简单的场景。

## 本地消息表

远程分布式事务拆分成一系列的本地事务，借助关系型数据库的表来实现。

第一步通过本地事务同步刷盘保证凭证消息插入消息表。第二步，通过高时效的MQ来通知对方，通知失败的用定时任务扫描消息表的数据，再次发送或者人工处理。消息消费者方面在消费状态表上记录消费状态，事务操作前先检查消息的消费状态，已消费则不执行，否则执行完后通过本地事务控制来更新消费状态表。（是不是也可以通过hashmap内存缓存去重+主键插入对消息去重？）

这种实现非常经典，基本上避免了分布式事务，实现了最终一致性。但是关系型数据库的吞吐量和性能不支持高并发场景下的写操作。

## 非事务消息
消息出列后，消费者端的业务要执行成功，否则消息不能丢失。消息的重复消费问题要解决。

主流的MQ产品都具有持久化消息的功能，消费失败可以重试。重复消费可以通过接口的幂等设计，以及消费日志或者状态表来实现。

这种方式比较常见，吞吐量和性能由于关系型数据库方案。

## 事务消息

除了前面的异常捕获和回滚的方式，还有RocketMQ的方法：

第一阶段发送Prepared消息时，会拿到消息的地址，第二阶段执行本地事务，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。

对于确认消息发送失败的情况，RocketMQ会定期扫描集群中的事务消息，这时候发现了prepared消息，就会想发送者确认，事务执行情况和消息处理策略。这样就保证了消息发送与本地事务同时成功或者同时失败。

目前的互联网电商几乎都是使用了类似的方法。主流的开源MQ都没有实现对事务消息的支持，RocketMQ的事务消息部分也没有开源。

## 其他补偿方式

类似于CAS的死循环重试，支付宝回调请求和一些MQ的重试补偿也是不断重试。对于成熟的系统，可用性很高，瞬时的网络故障和调用超时引起的问题，重试是很有效的解决方法。

致命异常则应记录详细的日志，并提高警戒等级，邮件通知人工处理。



## 什么是事务补偿

在事务链中的任何一个正向事务操作，都必须存在一个完全符合回滚规则的可逆事务。tcc-transaction)是基于补偿型事务的AP系统的一种实现, 具有最终一致性。

## redis怎么实现分布式锁？

multi, exec, discard, watch. 分布式事务则使用setnx 或者set nx



## 什么是2pc和3pc?

**二阶段提交**协议是一个强一致性算法，将提交过程分为2个阶段：

第一阶段：提交事务请求（投票阶段，如果参与者超时？）

1. 事务询问：协调者把事务拆分后，向参与者发送包含事务内容的请求，询问是否可以执行，并等待响应。
1. 执行事务：参与者执行事务，并把undo和redo日志写入事务日志。
1. 返回响应：参与者向协调者返回事务的执行结果。

第二阶段：执行事务提交（执行阶段）

1. 发送提交/回滚请求：协调者根据返回的执行结果，发送commit/rollback请求。
1. 事务提交：参与者执行事务提交/使用undo日志回滚，最后释放资源。
1. 反馈结果：参与者完成事务提交/回滚后，返回执行/回滚结果。
1. 完成事务：协调者收到所有参与者的ACK消息后，完成事务/中断。

二阶段提交提交的优点是：原理简单，容易实现。
缺点是：(其他参与者的)同步阻塞、(协调者的)单点问题、(网络异常或者机器崩溃导致)数据不一致、(用超时判断中断的容错机制)过于保守。

**三阶段提交**把提交事务请求阶段参与者执行事务的步骤拆分到增加的预提交阶段。

第一阶段：询问提交(CanCommit)协调者发送包含事务内容的的可行性询问请求，参与者返回评估结果(包括超时)。

第二阶段：预提交(PreCommit)协调者发送预提交/中断请求，参与者执行事务并记录日志，返回执行结果，并等待。或者中断事务，无需回滚。

第三阶段：提交(doCommit)协调者发送提交/中断请求，参与者提交/回滚事务，返回执行/回滚结果。这个阶段内，协调者因宕机或者网络故障不能按时发送提交/中断请求，参与者的容错机制是超时自动提交。（假设是提交请求？）

3PC相对于2PC的优点是通过增加预提交阶段，降低了参与者的阻塞范围，并在协调者出现单点故障后继续达成一致。缺点是第二阶段如果出现网络分区，被隔离的参与者会自动提交，使数据不一致。

## 一组进程提出一致性提案需要保证什么？

只有提出提案才会有选定，提出的提案只能选定一个，选定后提案信息公开而排除争议。

## 一致性协议的算法有那些？

paxos, raft, quorum等。



## Raft算法

Raft算法提供了和paxos算法相同的功能和性能，但算法结构不同，更容易理解和构建。

节点角色包括：领导者，选民，候选者。

算法分为2个阶段。刚启动或者领导者崩溃后，任何一个选民服务器都可以成为一个候选者，第一阶段，向选民服务器发出选举自己的请求，超过半数同意则成为领导者。第二阶段，执行领导者的任务，发布日志复制指令。

## Quorum NWR

Amazon的Dynamo云存储系统中的一致性解决方案。N:同一份数据的副本数，W:更新成功需要的副本数，R:读取数据需要的副本数。要求：W>N/2, W+R>N。保障高可用，就要求N>=3，数据不一致可以使用客户端时间戳等来解决。TFS非结构化存储系统的策略就是N=W=3，另外，节点挂掉后，复制数据块，在新节点恢复，异步cas写数据直到成功。

数据库的双写，kafka的复制，hdfs的副本，都是这样通过多机分发数据保证可靠性的，特点是没有即时刷盘，保证了高速。

## gossip流言协议

一种去中心化的集群节点的状态同步协议，解决了快速传播和状态一致的问题。实现简单，具有较高的容错性和性能。向最近的几个节点发送。

